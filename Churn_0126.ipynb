{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf9421d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean this up, many are unused\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "df_raw = pd.read_csv('BankChurners.csv')\n",
    "y = df_raw['Attrition_Flag'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e334f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Numerical Only\n",
      "15 with Sex\n",
      "22 with Education, should add 7 to 22\n",
      "26 with Marriage, should add 4 to 26\n",
      "32 with Income, should add 6 to 32\n",
      "36 with Card Color, should add 4 to 36\n",
      "(10127, 36)\n"
     ]
    }
   ],
   "source": [
    "cols = df_raw.describe().columns\n",
    "cols = cols.tolist()\n",
    "dfx = df_raw[cols[1:-2]]\n",
    "X_num = dfx.to_numpy()\n",
    "print(str(X_num.shape[1]) + ' Numerical Only')\n",
    "\n",
    "# categorical, Gender\n",
    "df_gender = pd.get_dummies(df_raw['Gender'])\n",
    "genF = df_gender['F'].to_numpy()\n",
    "Xf = np.append(X_num,genF.reshape((10127,1)),axis=1)\n",
    "print(str(Xf.shape[1]) + ' with Sex')\n",
    "\n",
    "# print(Xf.shape)\n",
    "df_edu = pd.get_dummies(df_raw['Education_Level'])\n",
    "edu = df_edu.to_numpy()\n",
    "# print(edu.shape)\n",
    "Xed = np.append(Xf,edu,axis=1)\n",
    "print(str(Xed.shape[1]) + ' with Education, should add 7 to 22')\n",
    "\n",
    "# categorical, Marriage\n",
    "# Put 4 columns because is divorced more likely than single to use this card, I dont think so\n",
    "mar = df_raw['Marital_Status'].unique()\n",
    "# print(mar)\n",
    "df_mar = pd.get_dummies(df_raw['Marital_Status'])\n",
    "# df_mar.head()\n",
    "mar = df_mar.to_numpy()\n",
    "# print(mar.shape)\n",
    "Xmar = np.append(Xed,mar,axis=1)\n",
    "print(str(Xmar.shape[1]) + ' with Marriage, should add 4 to 26')\n",
    "\n",
    "# categorical, Income\n",
    "# Put 6 columns because i am not sure if this should be ordinal but I am saying not.\n",
    "inc = df_raw['Income_Category'].unique()\n",
    "df_inc = pd.get_dummies(df_raw['Income_Category'])\n",
    "df_inc.head()\n",
    "inc = df_inc.to_numpy()\n",
    "Xinc = np.append(Xmar,inc,axis=1)\n",
    "print(str(Xinc.shape[1]) + ' with Income, should add 6 to 32')\n",
    "\n",
    "# categorical, Card Category\n",
    "# Put 6 columns because i am not sure if this should be ordinal but I am saying not, dont know what the order is.\n",
    "cc = df_raw['Card_Category'].unique()\n",
    "df_cc = pd.get_dummies(df_raw['Card_Category'])\n",
    "df_cc.tail()\n",
    "cc = df_cc.to_numpy()\n",
    "Xcc = np.append(Xinc,cc,axis=1)\n",
    "print(str(Xcc.shape[1]) + ' with Card Color, should add 4 to 36')\n",
    "\n",
    "\n",
    "# Final X, just rename\n",
    "X = Xcc\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726101f9",
   "metadata": {},
   "source": [
    "I will make a custom scorer for my hyperparameterizations to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f2a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_recall_score(y_test, y_pred):\n",
    "    return metrics.recall_score(y_test,y_pred, average=None)[0]\n",
    "\n",
    "c_score = make_scorer(custom_recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2b0da",
   "metadata": {},
   "source": [
    "<h3>First Model is the Random Forest - 62<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8226e631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.6171875  0.98696462]\n",
      "[[ 237  147]\n",
      " [  28 2120]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.89      0.62      0.73       384\n",
      "Existing Customer       0.94      0.99      0.96      2148\n",
      "\n",
      "         accuracy                           0.93      2532\n",
      "        macro avg       0.91      0.80      0.85      2532\n",
      "     weighted avg       0.93      0.93      0.93      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=8, random_state=0) # <-- max depth could be the problem\n",
    "clf.fit(X_train, y_train) #< fit on the train, score on the test\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb9b07",
   "metadata": {},
   "source": [
    "<h3>Second Model is the Hyperparameterized Random Forest - 79<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba96037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7fa5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=110, n_estimators=1000)\n",
      "13.535258480000001 minutes\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------- WARNING -- 14 Min run time --------------------------\n",
    "\n",
    "# Try Minimal, this one was garbage\n",
    "param_grid_rf = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 110],\n",
    "    'max_features': ['auto', 3],\n",
    "    'min_samples_leaf': [1,3],\n",
    "    'min_samples_split': [2, 8],\n",
    "    'n_estimators': [100, 1000]\n",
    "}\n",
    "\n",
    "tic = time.perf_counter() \n",
    "rf_model_grid = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                            param_grid=param_grid_rf, \n",
    "                            scoring=c_score,\n",
    "                            cv = 5,\n",
    "                            verbose=0)# verbose = 3 to read output\n",
    "\n",
    "rf_model_grid.fit(X_train, y_train)\n",
    "print(rf_model_grid.best_estimator_)\n",
    "\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(str( (toc - tic)/60) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd963e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.7890625  0.98696462]\n",
      "[[ 303   81]\n",
      " [  28 2120]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.92      0.79      0.85       384\n",
      "Existing Customer       0.96      0.99      0.97      2148\n",
      "\n",
      "         accuracy                           0.96      2532\n",
      "        macro avg       0.94      0.89      0.91      2532\n",
      "     weighted avg       0.96      0.96      0.96      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From Grid Search\n",
    "# clf_h = RandomForestClassifier(max_depth=110,\n",
    "#                                n_estimators=1000)\n",
    "\n",
    "# This one is better for some reason\n",
    "clf_h = RandomForestClassifier(max_depth=110,\n",
    "                               random_state=13)\n",
    "\n",
    "\n",
    "y_pred = clf_h.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bef1a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=80, max_features=3, min_samples_leaf=3,\n",
      "                       min_samples_split=8, n_estimators=300)\n",
      "0.6347778209612643\n",
      "2.1551986700000003 minutes\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------  2 Min run time --------------------------\n",
    "\n",
    "param_dist = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [2, 3, 4, 5, 8],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "tic = time.perf_counter()\n",
    "rf_random_search = RandomizedSearchCV(estimator=RandomForestClassifier(),\n",
    "                                   param_distributions=param_dist,\n",
    "                                   scoring=c_score,\n",
    "                                   cv = 5,\n",
    "                                   verbose=0,\n",
    "                                   n_iter=10)\n",
    "\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "print(rf_random_search.best_estimator_)\n",
    "print(rf_random_search.best_score_)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(str( (toc - tic)/60) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5afb5dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.6015625  0.99022346]\n",
      "[[ 231  153]\n",
      " [  21 2127]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.92      0.60      0.73       384\n",
      "Existing Customer       0.93      0.99      0.96      2148\n",
      "\n",
      "         accuracy                           0.93      2532\n",
      "        macro avg       0.92      0.80      0.84      2532\n",
      "     weighted avg       0.93      0.93      0.93      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for some reason this gives a different answer (59) from above (63)\n",
    "# clf_rand = RandomForestClassifier(max_depth=90, max_features=3, min_samples_leaf=2,\n",
    "#                                   min_samples_split=8, n_estimators=1000,\n",
    "#                                   random_state=43)\n",
    "\n",
    "# I just grabbed this to see.\n",
    "clf_rand = RandomForestClassifier(max_depth=110,\n",
    "                                  max_features=3,\n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=10,\n",
    "                                  n_estimators=100,\n",
    "                                  random_state=13)\n",
    "\n",
    "y_pred = clf_rand.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d0f0a6",
   "metadata": {},
   "source": [
    "<h3>The third model is the Naive Bayes Classifier - 63<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "038b6157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.6328125  0.92225326]\n",
      "[[ 243  141]\n",
      " [ 167 1981]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.59      0.63      0.61       384\n",
      "Existing Customer       0.93      0.92      0.93      2148\n",
      "\n",
      "         accuracy                           0.88      2532\n",
      "        macro avg       0.76      0.78      0.77      2532\n",
      "     weighted avg       0.88      0.88      0.88      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb8ecc",
   "metadata": {},
   "source": [
    "<h3>The fourth model is the Hyperparameterized Naive Bayes Classifier - 63<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c987d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'priors': None, 'var_smoothing': 1e-09}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c99096c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.001873817422860383)\n",
      "0.3943668549999984 minutes\n"
     ]
    }
   ],
   "source": [
    "param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "\n",
    "nbModel_grid = GridSearchCV(estimator=GaussianNB(), \n",
    "                            param_grid=param_grid_nb, \n",
    "                            scoring=c_score,\n",
    "                            cv = 10,\n",
    "                            verbose=0)# verbose = 3 to read output\n",
    "tic = time.perf_counter()\n",
    "\n",
    "nbModel_grid.fit(X_train, y_train)\n",
    "print(nbModel_grid.best_estimator_)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(str( (toc - tic)/60) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93c31ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.6328125  0.92225326]\n",
      "[[ 243  141]\n",
      " [ 167 1981]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.59      0.63      0.61       384\n",
      "Existing Customer       0.93      0.92      0.93      2148\n",
      "\n",
      "         accuracy                           0.88      2532\n",
      "        macro avg       0.76      0.78      0.77      2532\n",
      "     weighted avg       0.88      0.88      0.88      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gnbh = GaussianNB(var_smoothing=0.000000001)  <--- Defaults\n",
    "gnbh = GaussianNB(var_smoothing=0.001873817422860383)\n",
    "y_pred = gnbh.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a330a75c",
   "metadata": {},
   "source": [
    "<h3>Fifth Model is the Logistic Regression - 60<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "056c901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.59895833 0.95949721]\n",
      "[[ 230  154]\n",
      " [  87 2061]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.73      0.60      0.66       384\n",
      "Existing Customer       0.93      0.96      0.94      2148\n",
      "\n",
      "         accuracy                           0.90      2532\n",
      "        macro avg       0.83      0.78      0.80      2532\n",
      "     weighted avg       0.90      0.90      0.90      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "y_pred = logreg.fit(X_train,y_train).predict(X_test)\n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a0be5",
   "metadata": {},
   "source": [
    "<h3>Fifth is the Logistic Regression with Hyperparameterization - 60<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec68e784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             scoring=make_scorer(custom_recall_score))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {\n",
    "#     'penalty' : ['none'], \n",
    "#     'C'       : np.logspace(-3,3,7),\n",
    "#     'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "#     'max_iter': [1000000]\n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    'C'       : np.logspace(-3,3,7),\n",
    "    'solver'  : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "clf = GridSearchCV(logreg,                    # model\n",
    "                   param_grid = parameters,   # hyperparameters\n",
    "                   scoring=c_score,           # metric for scoring ---> used to be 'recall', does not work\n",
    "                   cv = 10,                   # something with cross validation, higher gets better score\n",
    "                   verbose=0) # verbose = 3 to read output\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13745bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hyperparameters : {'C': 10.0, 'solver': 'newton-cg'}\n",
      "Recall : 0.5993677419354839\n"
     ]
    }
   ],
   "source": [
    "print(\"Tuned Hyperparameters :\", clf.best_params_)\n",
    "print(\"Recall :\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b8ff9c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: [0.59895833 0.95810056]\n",
      "[[ 230  154]\n",
      " [  90 2058]]\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Attrited Customer       0.72      0.60      0.65       384\n",
      "Existing Customer       0.93      0.96      0.94      2148\n",
      "\n",
      "         accuracy                           0.90      2532\n",
      "        macro avg       0.82      0.78      0.80      2532\n",
      "     weighted avg       0.90      0.90      0.90      2532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logreg = LogisticRegression(C = 1.0, solver = 'lbfgs') # <---Defaults\n",
    "logreg = LogisticRegression(C = 10.0, solver = 'newton-cg')\n",
    "y_pred = logreg.fit(X_train,y_train).predict(X_test)\n",
    "# y_pred = logreg.predict(X_test)\n",
    "print(\"Recall:\",metrics.recall_score(y_test,y_pred, average=None))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5580eefd",
   "metadata": {},
   "source": [
    "<h3>Questions</h3>\n",
    "<ol>\n",
    "  <li>Random Forest - Why does the grid search not give the best answer?</li>\n",
    "  <li>Why does the random_state variable have so much control over outcomes?</li>  \n",
    "  <li>Others - Why did hyperparameterization not improve the model?</li>\n",
    "  <li>How do I determine the range for parameters of a model, I am copying and guessing?</li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
